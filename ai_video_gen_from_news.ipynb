{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVADzFULDt9O5WOrur0MiX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navonilmandal/AI-driven-automated-News-Video-Generator-pipeline./blob/main/ai_video_gen_from_news.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWlEqzl600m4",
        "outputId": "7dbe810e-3521-41b4-80e9-2ce34c5891b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/81.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Colab cell 1\n",
        "!pip install -q requests feedparser beautifulsoup4 python-dateutil\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 2\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgTRfEJG25XG",
        "outputId": "73b3d2d4-7d04-452b-f2d2-d2db0137ade1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 3: securely read API keys (enter blank to skip)\n",
        "import getpass, os\n",
        "NEWSAPI_KEY = getpass.getpass(\"Enter your NewsAPI key (press Enter to skip): \")\n",
        "# for future steps (script generation), you'll need OpenAI key\n",
        "OPENAI_KEY = getpass.getpass(\"Enter your OpenAI key (press Enter to skip): \")\n",
        "\n",
        "# set in env for convenience (only for this Colab session)\n",
        "if NEWSAPI_KEY:\n",
        "    os.environ[\"NEWSAPI_KEY\"] = NEWSAPI_KEY\n",
        "if OPENAI_KEY:\n",
        "    os.environ[\"OPENAI_KEY\"] = OPENAI_KEY\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3q9yxO73Ez_",
        "outputId": "045992de-372a-440a-bb1f-1ed8e7ca1522"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your NewsAPI key (press Enter to skip): ··········\n",
            "Enter your OpenAI key (press Enter to skip): ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 4: optimized scraper function (works with NewsAPI if key given, else Google News RSS)\n",
        "import os, json, logging\n",
        "from typing import List, Dict, Optional\n",
        "from datetime import datetime\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "import requests, feedparser\n",
        "from bs4 import BeautifulSoup\n",
        "from dateutil import parser as dateparse\n",
        "from requests.adapters import HTTPAdapter\n",
        "from urllib3.util.retry import Retry\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
        "\n",
        "NEWSAPI_URL = \"https://newsapi.org/v2/top-headlines\"\n",
        "GOOGLE_NEWS_RSS = \"https://news.google.com/rss?hl=en-IN&gl=IN&ceid=IN:en\"\n",
        "DEFAULT_TIMEOUT = 10\n",
        "\n",
        "def requests_session_with_retries(total_retries: int = 3, backoff_factor: float = 0.3):\n",
        "    sess = requests.Session()\n",
        "    retries = Retry(\n",
        "        total=total_retries,\n",
        "        backoff_factor=backoff_factor,\n",
        "        status_forcelist=(429, 500, 502, 503, 504),\n",
        "        allowed_methods=[\"GET\", \"POST\"]\n",
        "    )\n",
        "    sess.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
        "    sess.mount(\"http://\", HTTPAdapter(max_retries=retries))\n",
        "    return sess\n",
        "\n",
        "def clean_html(html: Optional[str]) -> str:\n",
        "    if not html:\n",
        "        return \"\"\n",
        "    s = BeautifulSoup(html, \"html.parser\")\n",
        "    text = s.get_text(separator=\" \", strip=True)\n",
        "    return \" \".join(text.split())\n",
        "\n",
        "def normalize_date(datestr: Optional[str]) -> Optional[str]:\n",
        "    if not datestr:\n",
        "        return None\n",
        "    try:\n",
        "        dt = dateparse.parse(datestr)\n",
        "        return dt.isoformat()\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def _make_key(title: str, link: str) -> str:\n",
        "    return (title or \"\").strip().lower() + \"|\" + (link or \"\").strip().lower()\n",
        "\n",
        "def fetch_from_newsapi(api_key: str, country: str = \"in\", page_size: int = 8) -> List[Dict]:\n",
        "    sess = requests_session_with_retries()\n",
        "    params = {\"apiKey\": api_key, \"country\": country, \"pageSize\": page_size}\n",
        "    try:\n",
        "        resp = sess.get(NEWSAPI_URL, params=params, timeout=DEFAULT_TIMEOUT)\n",
        "        resp.raise_for_status()\n",
        "        data = resp.json()\n",
        "        articles = []\n",
        "        for a in data.get(\"articles\", [])[:page_size]:\n",
        "            articles.append({\n",
        "                \"title\": clean_html(a.get(\"title\") or \"\"),\n",
        "                \"link\": a.get(\"url\"),\n",
        "                \"summary\": clean_html(a.get(\"description\") or a.get(\"content\") or \"\"),\n",
        "                \"published\": normalize_date(a.get(\"publishedAt\")),\n",
        "                \"source\": (a.get(\"source\") or {}).get(\"name\") or \"NewsAPI\"\n",
        "            })\n",
        "        return articles\n",
        "    except Exception as e:\n",
        "        logging.warning(\"NewsAPI fetch failed: %s\", e)\n",
        "        return []\n",
        "\n",
        "def fetch_from_google_rss(rss_url: str = GOOGLE_NEWS_RSS, max_items: int = 10) -> List[Dict]:\n",
        "    try:\n",
        "        feed = feedparser.parse(rss_url)\n",
        "        items = []\n",
        "        for entry in feed.entries[:max_items]:\n",
        "            items.append({\n",
        "                \"title\": clean_html(entry.get(\"title\", \"\")),\n",
        "                \"link\": entry.get(\"link\", \"\"),\n",
        "                \"summary\": clean_html(entry.get(\"summary\", \"\") or entry.get(\"description\", \"\")),\n",
        "                \"published\": normalize_date(entry.get(\"published\") or entry.get(\"updated\")),\n",
        "                \"source\": (entry.get(\"source\") or {}).get(\"title\") if entry.get(\"source\") else urlparse(entry.get(\"link\", \"\")).netloc\n",
        "            })\n",
        "        return items\n",
        "    except Exception as e:\n",
        "        logging.warning(\"Google RSS fetch failed: %s\", e)\n",
        "        return []\n",
        "\n",
        "def get_trending_news(top_k: int = 6, newsapi_key: Optional[str] = None) -> List[Dict]:\n",
        "    top_k = int(top_k)\n",
        "    results = []\n",
        "    # 1) try NewsAPI if provided\n",
        "    if newsapi_key:\n",
        "        logging.info(\"Using NewsAPI...\")\n",
        "        results = fetch_from_newsapi(newsapi_key, page_size=top_k)\n",
        "        if len(results) >= top_k:\n",
        "            return results[:top_k]\n",
        "    # 2) fallback and supplement with RSS\n",
        "    logging.info(\"Using Google News RSS fallback/supplement...\")\n",
        "    rss = fetch_from_google_rss(max_items=top_k*2)\n",
        "    seen = set()\n",
        "    merged = []\n",
        "    for a in (results + rss):\n",
        "        key = _make_key(a.get(\"title\",\"\"), a.get(\"link\",\"\"))\n",
        "        if key in seen:\n",
        "            continue\n",
        "        seen.add(key)\n",
        "        merged.append(a)\n",
        "        if len(merged) >= top_k:\n",
        "            break\n",
        "    return merged\n",
        "\n",
        "# Convenience: run and save\n",
        "def fetch_and_save(top_k: int = 6, save_path: str = \"trending_news.json\"):\n",
        "    key = os.environ.get(\"NEWSAPI_KEY\", \"\") or \"\"\n",
        "    articles = get_trending_news(top_k=top_k, newsapi_key=key if key else None)\n",
        "    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(articles, f, ensure_ascii=False, indent=2)\n",
        "    logging.info(\"Saved %d articles to %s\", len(articles), save_path)\n",
        "    return articles\n",
        "\n",
        "# Example run (uncomment to run here)\n",
        "# articles = fetch_and_save(top_k=6, save_path=\"/content/trending_news.json\")\n",
        "# print(articles[:2])\n"
      ],
      "metadata": {
        "id": "e7QSJyqc3qmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 5: run the fetch, save to local or Drive\n",
        "articles = fetch_and_save(top_k=6, save_path=\"/content/trending_news.json\")\n",
        "print(\"Fetched:\", len(articles))\n",
        "for i,a in enumerate(articles, start=1):\n",
        "    print(f\"\\n[{i}] {a['title']}\\nSource: {a['source']}\\nLink: {a['link']}\\nSummary: {a['summary'][:200]}...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vpKjYQy3t-y",
        "outputId": "7ea9f930-442d-4f7d-abe0-197eaf03d1cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched: 6\n",
            "\n",
            "[1] Mamata Banerjee demands PM’s apology over ‘Bankim da’ remark in Lok Sabha - The Hindu\n",
            "Source: The Hindu\n",
            "Link: https://news.google.com/rss/articles/CBMi2AFBVV95cUxPMkdBLUttOGRhZjN4eWNlekFkTnNRWXgyZ1kteXJLd2Nmdy1DQV9QRDlvRTVKZ1Q5UHpobVF5X3FZLVcwLW51Zy1NSUdrMEZPNXFEOWtwUVozdDNoa2ZqRFZqVHJQclg3bExUd1dNMmUxVVFmZWZSd1RsNFNCWDJiczZRZWhNVE1VVl9aNnVyS1l3T0JIVXpjVnF4dTZHdDFaOEZ3UlNSamZONkU1VXEzUzdqMl9xYWM3MnNfOVlyWDRSSHVZajZiVkdKaTRFSTFmRmxBMEp0UkjSAd8BQVVfeXFMTXRUV2t4SU5IUlZFMWxvTWhvUExMSVJFQ2FyZ2JkRUhWV0tQNlZNanFodTZaYjVqZEgzMUNLU2Z1WC1UZ3E3d2tTZEJ3Q1Vmckl1MWQ3UWY5U1NkV0FfYk9HYU1BQ1BFU2xFUkZ5dVpHbzk4Sm1pV1lZMmN0Sy15MWJIaGJuSUttVXhIalA4NFpwUjB1OGt0Y1M2WTA3R1BPckdnNVhkeEd1YXljRjFwdFVhTF9WcDJKTVEyR0hKUWZRM1Vpc05jaC1uS3A2QWhwMmZBT3Nsa1NSNF96TDN5aw?oc=5\n",
            "Summary: Mamata Banerjee demands PM’s apology over ‘Bankim da’ remark in Lok Sabha The Hindu Amit Shah Rebuts Priyanka Gandhi On Vande Mataram, Slams Nehru, Indira Gandhi NDTV 'Vande Mataram' debate: TMC MPs h...\n",
            "\n",
            "[2] How Goa nightclub owners Saurabh, Gaurav Luthra managed to escape by flight to Thailand within hours after fire | India News - Hindustan Times\n",
            "Source: Hindustan Times\n",
            "Link: https://news.google.com/rss/articles/CBMihAJBVV95cUxPZ25EUENTaEEtN081OUdCandOOGJBWC1xdU9HVUI0NnJYSE9oVUQwd0pncU5ZOUxOQURJVS1CQ1d3RmJJbTFNcnRoY3F3cS1TQ0NzTGJkeEthQnBpWVhiX0lKVWVzMnZmc2JhN1dCWUFsYW54Rzl6cTFmX1pKWThyRlhCazF0WGNDalhEaEhZRmZBYzcwWkhNcU84bVBwa21lZjJtYndKc3FIVGQxTFZkMzVfT2M3SkpybHZoX2pPZXRIUDJ4Q25SVWUtUERnSTZzZ19GR1lZcEhsd3FmVW95c1FqRF9fUllyT05Bdm5GSk1oMTZTR0Vsd1p6X2x4UGVLOVd5ZA?oc=5\n",
            "Summary: How Goa nightclub owners Saurabh, Gaurav Luthra managed to escape by flight to Thailand within hours after fire | India News Hindustan Times Demolition Begins At 2nd Club Owned By Luthras, Missing Sin...\n",
            "\n",
            "[3] From CJI to CCTV: Rahul Gandhi's 3 questions and 4 demands in SIR Parliament debate | India News - Hindustan Times\n",
            "Source: Hindustan Times\n",
            "Link: https://news.google.com/rss/articles/CBMi3AFBVV95cUxQUFVuQnphOUtzNDliRXUwZUIyM00xbVJhRU9iMDdvSmxkM2pHLUM2a3h3QlZDdU5iY3d4S1hYYmhkdVZZcV9CZG5oM2twTDI2Y29LTm1TWDJKYk1naGZmSWU4SmtaRjYzam8yeC1aM015a3daOWRLTDVyNGhxbjRwaUdmN1g2bDk2aEJSNnFYSGxNX0RhVWtvcEl1Y09WbUFVUFFTQVdnV19vUVM0YnByUmlaT2lwbm9NX2xyb01NSHFhU3phQUNZTncxbzQyQUhPV3lnSW9KSnJWaFhq0gHiAUFVX3lxTE5tZmtkTFFLdjBKRURVNGpIdmluTnREQzNURW9UUkQ3Znptdy05YUUwbzFrenRLNW5MREVOZzVXZVZCRkE2bkRnMHU4enhCdmpSSnlVdGItYWZ4cWJtamkyWDFVZi1ZWVEtNXJXcFlqWlRJRGFaOF9rcFZYbU9Bc09QaDktQXJIemdPZnJieEtyb09GY2dtZzJGaEFFYjJJT0dqb2llcHFaRjM2VEpIV01EaUd0endCeERSSk1PaV9uUEcxQkFaYWk4V1kyODhrWDV0QkNLWnVKU0Y0RlNhT19nTFE?oc=5\n",
            "Summary: From CJI to CCTV: Rahul Gandhi's 3 questions and 4 demands in SIR Parliament debate | India News Hindustan Times \"No Bigger Anti-National Act Than Vote Chori\": Rahul Gandhi Attacks BJP NDTV 'Vote chor...\n",
            "\n",
            "[4] H-1B visa applicants asked to reschedule appointments as social media vetting policy begins from December 15 - CNBC TV18\n",
            "Source: CNBC TV18\n",
            "Link: https://news.google.com/rss/articles/CBMi5wFBVV95cUxQNElHcHNqTU0zNC1IOGFiWm1CYTIybkpGMjd3dUlmTlE4a2tmbmVzMTkyUi16a1FFd2RLUUtIWWxrN3VvVlFZbzRJRUVGTmVnUkRHTVhrbXpZN0x0UWF3T24zRG1rTjhoREdBNFlZYWZ4dWh6ODNGOWpwejNaWDEwOEZiamhDc1I3Y2IwV0JaNUdLN2xPVXFVb1NJRDZxRGdXSTRIcWgybE9HQW5tLWhFUmtubTZVZ2RsdUs5LXVweFJtVHpNQ1R0eElqejY0cFcxczRaSXQzMlZiVHVXZXE0bngxbzkyTGfSAewBQVVfeXFMTnd3aDBLNjFLbTkwQ2N1SWtTa2VGbzB5bE1udjFaaDIwZDg3Wl83Z2hnWmNRbTdNRkE2QklGaGJnNVp3X3d2NmhwSWxuS2M0aUwtcVVWVjFyeW1jNVpGOE9oQjhXY1pWRk9OM3VaeVhnMzMyZ2VmbnNuOVQzZk1HTk54MFJuRkd0Nkh2UnRsdVNaMnUyN284b1VPOUJZTUFJdUxSdTFxS01yZDRnUVlFMU1vNWVWdXktVmpTNUlDMjhNbExldjhIdkxkNDB0M00tNWZIOVRfRkhTc2V4b0lxNlB2TC1CRVJuRC15ZEQ?oc=5\n",
            "Summary: H-1B visa applicants asked to reschedule appointments as social media vetting policy begins from December 15 CNBC TV18 H-1B visa appointments cancelled for many applicants as US expands social media v...\n",
            "\n",
            "[5] Trump threatens more tariffs on Indian rice! Why India has little to worry - and US consumers may bear th - The Times of India\n",
            "Source: The Times of India\n",
            "Link: https://news.google.com/rss/articles/CBMioAJBVV95cUxNU1k4YzlxTDBubExYdWhLSzd3c0xwN3k4VF9zU3paX0t4UlJlbFY0eG5MMDlYRnlIck5xNWxVai0xREJORk0xRjhIQm92MFBEVW9VcFd2WW9RODF1VV82Z0pEd3RDUHNkNTNXRTdxODY5RXU1WjJTQzF3MkJSWnJWNHRIUm5NNl9UNUR6aDRYcU96VGk3LXVqMWJBUU0xc2ZXQnFDNUl4cHFoMzJtZ19GTzlSTVVldHJJMDlib2lSUEx5ZUVRQUl3UXBOWjlIS2VzbkNfb3RCSURxOWpIaklXSDROcjlnYURrTDQyUFYwQ1RBcnY0a0oyaXF6LVlzU0hGbGpvZ3hQTXhqdTVveXR2cEJ1SnYzeHhhSkR0WmFKLTM?oc=5\n",
            "Summary: Trump threatens more tariffs on Indian rice! Why India has little to worry - and US consumers may bear th The Times of India Trumps Rice Tariff Threat: Wake Up And Smell The Basmati, Warn Exporters ND...\n",
            "\n",
            "[6] Raman Pillai: The celeb lawyer who helped actor Dileep walk scot-free - The News Minute\n",
            "Source: The News Minute\n",
            "Link: https://news.google.com/rss/articles/CBMiqgFBVV95cUxPVEwySUsxOGxKMnJqZl92LTFaNmhkVUZKT09Ia2RrYl9JcTByZ0ZCd09XR3V2STNLbklCNDlzaGxWTldVcmc0REhQZktwWTcycF9tYmlOMGJsNmJqRjFtMk5CSWxMc3pyVnlGdWVDNXRRNXVpcmd5Qk1PczlFS1VTem82T1hiSnZOOG1QMUF3N21oZ1QxRkU4ZVZOSHRXa2tLQjgxaVlCRFlSZw?oc=5\n",
            "Summary: Raman Pillai: The celeb lawyer who helped actor Dileep walk scot-free The News Minute Adoor Prakash’s remark rewrites poll-day narrative in central Travancore The Hindu Saddened but not surprised: Pra...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell: install/upgrade the modern OpenAI client\n",
        "!pip install -q --upgrade openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxcTN6e03-En",
        "outputId": "87220ee7-e7c7-499a-e252-202c61ebcd49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.0 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 2: securely read OpenAI key (press Enter to skip)\n",
        "import os, getpass\n",
        "OPENAI_KEY = os.environ.get(\"OPENAI_KEY\") or getpass.getpass(\"Enter your OpenAI key (press Enter to skip): \")\n",
        "if OPENAI_KEY:\n",
        "    os.environ[\"OPENAI_KEY\"] = OPENAI_KEY\n",
        "    print(\"OpenAI key set for this session.\")\n",
        "else:\n",
        "    print(\"No OpenAI key provided — using local fallback.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdWyGnJE4XTr",
        "outputId": "d7da3f39-6cc1-4cd1-f964-ee39139746b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI key set for this session.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell: updated script generator (works with openai>=1.0.0) and no NLTK fallback\n",
        "\n",
        "import os, time, json, logging, re\n",
        "from typing import Dict, List, Optional\n",
        "from functools import wraps\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
        "\n",
        "# read OPENAI_KEY from env (you already set via getpass earlier)\n",
        "OPENAI_KEY = os.environ.get(\"OPENAI_KEY\") or \"\"\n",
        "client = None\n",
        "\n",
        "if OPENAI_KEY:\n",
        "    try:\n",
        "        # New client style for openai>=1.0.0\n",
        "        from openai import OpenAI\n",
        "        client = OpenAI(api_key=OPENAI_KEY)\n",
        "        logging.info(\"OpenAI client initialized.\")\n",
        "    except Exception as e:\n",
        "        logging.warning(\"Failed to initialize OpenAI client: %s\", e)\n",
        "        client = None\n",
        "else:\n",
        "    logging.info(\"No OpenAI key found; will use fallback generator only.\")\n",
        "\n",
        "# --- retry decorator ---\n",
        "def retry_on_exception(max_retries=3, base_delay=1.0, allowed_exceptions=(Exception,)):\n",
        "    def deco(func):\n",
        "        @wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            delay = base_delay\n",
        "            for attempt in range(1, max_retries + 1):\n",
        "                try:\n",
        "                    return func(*args, **kwargs)\n",
        "                except allowed_exceptions as e:\n",
        "                    logging.warning(\"Attempt %d/%d failed: %s\", attempt, max_retries, e)\n",
        "                    if attempt == max_retries:\n",
        "                        raise\n",
        "                    time.sleep(delay)\n",
        "                    delay *= 2\n",
        "        return wrapper\n",
        "    return deco\n",
        "\n",
        "# --- OpenAI-based generator (modern client) ---\n",
        "@retry_on_exception(max_retries=3, base_delay=1.0, allowed_exceptions=(Exception,))\n",
        "def generate_script_openai(title: str, summary: str, tone: str = \"neutral, engaging\", word_target: int = 110) -> str:\n",
        "    \"\"\"\n",
        "    Uses modern OpenAI client (OpenAI()) and chat completions endpoint.\n",
        "    \"\"\"\n",
        "    if client is None:\n",
        "        raise RuntimeError(\"OpenAI client not available\")\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You are a concise, engaging news narrator for short-form videos. \"\n",
        "        \"Produce a single short narration suitable for a 30–60 second video.\"\n",
        "    )\n",
        "    user_prompt = (\n",
        "        f\"Headline: {title}\\n\\n\"\n",
        "        f\"Summary/Context: {summary}\\n\\n\"\n",
        "        \"Requirements:\\n\"\n",
        "        f\"- Produce ~{word_target} words (approximate) — enough for a 30–60 second spoken narration.\\n\"\n",
        "        \"- Use short, clear sentences. No bullet lists or extra sections.\\n\"\n",
        "        \"- Start with a 1-line hook (1 short sentence) to grab attention.\\n\"\n",
        "        \"- Then provide 2–3 sentences that explain the core info.\\n\"\n",
        "        \"- End with one 1-line closing sentence (a concise wrap-up or call-to-action).\\n\"\n",
        "        f\"- Tone: {tone}.\\n\"\n",
        "        \"Return only the narration text. Do not add metadata or commentary.\"\n",
        "    )\n",
        "\n",
        "    # new API: client.chat.completions.create(...)\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        max_tokens=320,\n",
        "        temperature=0.25\n",
        "    )\n",
        "    # response shape: resp.choices[0].message.content\n",
        "    text = resp.choices[0].message.get(\"content\") if resp.choices else None\n",
        "    if not text:\n",
        "        # fallback to raw string if different shape\n",
        "        text = str(resp)\n",
        "    return text.strip()\n",
        "\n",
        "# --- Local fallback: regex sentence splitter (no NLTK) ---\n",
        "def split_sentences_regex(text: str) -> List[str]:\n",
        "    \"\"\"Split text into sentences using punctuation-based regex.\"\"\"\n",
        "    if not text:\n",
        "        return []\n",
        "    # split on end-of-sentence punctuation followed by whitespace\n",
        "    sents = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
        "    # filter empties and trim\n",
        "    return [s.strip() for s in sents if s.strip()]\n",
        "\n",
        "def generate_script_fallback(title: str, summary: str, tone: str = \"neutral, engaging\", word_target: int = 110) -> str:\n",
        "    \"\"\"\n",
        "    Lightweight fallback that avoids NLTK and aims for a 30-60s narration.\n",
        "    \"\"\"\n",
        "    summary = (summary or \"\").strip()\n",
        "    if not summary:\n",
        "        hook = title if len(title.split()) <= 12 else \"Here's a quick update:\"\n",
        "        return f\"{hook} {title}. Stay tuned for more updates.\"\n",
        "\n",
        "    sents = split_sentences_regex(summary)\n",
        "    # prefer first 2-4 short sentences\n",
        "    selected = []\n",
        "    for sent in sents:\n",
        "        if len(selected) >= 3:\n",
        "            break\n",
        "        # ignore extremely long sentences; instead chop at commas if necessary\n",
        "        if len(sent.split()) > 45:\n",
        "            parts = re.split(r',\\s*', sent)\n",
        "            candidate = parts[0].strip() + ('.' if not parts[0].strip().endswith(('.', '!', '?')) else '')\n",
        "            selected.append(candidate)\n",
        "        else:\n",
        "            selected.append(sent if sent.endswith(('.', '!', '?')) else sent + '.')\n",
        "\n",
        "    hook = title if len(title.split()) <= 12 else \"Here's an update:\"\n",
        "    body = \" \".join(selected).strip()\n",
        "    closing = \"Stay tuned for more updates.\"\n",
        "    script = f\"{hook} {body} {closing}\"\n",
        "\n",
        "    # crude word-trim to approximate word_target\n",
        "    words = script.split()\n",
        "    if len(words) > word_target + 20:\n",
        "        script = \" \".join(words[:word_target]).rstrip()\n",
        "        if not script.endswith(('.', '!', '?')):\n",
        "            script = script + '.'\n",
        "    return script\n",
        "\n",
        "# --- unified generator ---\n",
        "def generate_script(title: str, summary: str, tone: str = \"neutral, engaging\", word_target: int = 110) -> str:\n",
        "    try:\n",
        "        if client:\n",
        "            return generate_script_openai(title=title, summary=summary, tone=tone, word_target=word_target)\n",
        "    except Exception as e:\n",
        "        logging.warning(\"OpenAI generation failed, using fallback: %s\", e)\n",
        "    return generate_script_fallback(title=title, summary=summary, tone=tone, word_target=word_target)\n",
        "\n",
        "# --- batch util ---\n",
        "def batch_generate_scripts(articles: List[Dict], tone: str = \"neutral, engaging\", word_target: int = 110,\n",
        "                           out_path: str = \"/content/generated_scripts.json\") -> List[Dict]:\n",
        "    results = []\n",
        "    for idx, a in enumerate(articles):\n",
        "        title = a.get(\"title\") or \"\"\n",
        "        summary = a.get(\"summary\") or \"\"\n",
        "        logging.info(\"Generating script %d/%d: %s\", idx+1, len(articles), title[:80])\n",
        "        try:\n",
        "            script_text = generate_script(title, summary, tone=tone, word_target=word_target)\n",
        "        except Exception as e:\n",
        "            logging.error(\"Generation failed for article %d: %s\", idx+1, e)\n",
        "            script_text = generate_script_fallback(title, summary, tone=tone, word_target=word_target)\n",
        "        entry = dict(a)\n",
        "        entry[\"script\"] = script_text\n",
        "        results.append(entry)\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
        "    logging.info(\"Saved %d scripts to %s\", len(results), out_path)\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "jvghCV5U4aKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell: Robust OpenAI extraction + generator (replace previous version)\n",
        "import os, time, logging, re\n",
        "from functools import wraps\n",
        "from typing import List, Dict\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
        "\n",
        "# use OpenAI client if configured\n",
        "OPENAI_KEY = os.environ.get(\"OPENAI_KEY\") or \"\"\n",
        "client = None\n",
        "if OPENAI_KEY:\n",
        "    try:\n",
        "        from openai import OpenAI\n",
        "        client = OpenAI(api_key=OPENAI_KEY)\n",
        "        logging.info(\"OpenAI client initialized.\")\n",
        "    except Exception as e:\n",
        "        logging.warning(\"Failed to initialize OpenAI client: %s\", e)\n",
        "        client = None\n",
        "else:\n",
        "    logging.info(\"No OpenAI key found; will use fallback generator only.\")\n",
        "\n",
        "def retry_on_exception(max_retries=3, base_delay=1.0, allowed_exceptions=(Exception,)):\n",
        "    def deco(func):\n",
        "        @wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            delay = base_delay\n",
        "            for attempt in range(1, max_retries + 1):\n",
        "                try:\n",
        "                    return func(*args, **kwargs)\n",
        "                except allowed_exceptions as e:\n",
        "                    logging.warning(\"Attempt %d/%d failed: %s\", attempt, max_retries, e)\n",
        "                    if attempt == max_retries:\n",
        "                        raise\n",
        "                    time.sleep(delay)\n",
        "                    delay *= 2\n",
        "        return wrapper\n",
        "    return deco\n",
        "\n",
        "def _extract_text_from_choice(choice) -> str:\n",
        "    \"\"\"\n",
        "    Return the message text from various SDK shapes:\n",
        "    - choice.message (object) with .content\n",
        "    - choice.message (dict) with ['content']\n",
        "    - choice.get('message') ...\n",
        "    - choice.text or choice.get('text') (older style)\n",
        "    - finally, str(choice)\n",
        "    \"\"\"\n",
        "    # 1) try common attribute path: choice.message.content\n",
        "    try:\n",
        "        msg = getattr(choice, \"message\", None)\n",
        "        if msg is not None:\n",
        "            # if msg is a dict-like\n",
        "            if isinstance(msg, dict):\n",
        "                content = msg.get(\"content\")\n",
        "                if content:\n",
        "                    return content\n",
        "            # if msg is an object with .content\n",
        "            content = getattr(msg, \"content\", None)\n",
        "            if content:\n",
        "                return content\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # 2) try attribute on choice itself: .message.content (already tried) or .text\n",
        "    try:\n",
        "        txt = getattr(choice, \"text\", None)\n",
        "        if txt:\n",
        "            return txt\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # 3) try dict-like access\n",
        "    try:\n",
        "        if isinstance(choice, dict):\n",
        "            # older response may be {'message': {'content': '...'}}\n",
        "            msg = choice.get(\"message\")\n",
        "            if isinstance(msg, dict):\n",
        "                c = msg.get(\"content\")\n",
        "                if c:\n",
        "                    return c\n",
        "            # older 'text' field\n",
        "            t = choice.get(\"text\")\n",
        "            if t:\n",
        "                return t\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # 4) fallback: try str(choice)\n",
        "    try:\n",
        "        return str(choice)\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "@retry_on_exception(max_retries=3, base_delay=1.0, allowed_exceptions=(Exception,))\n",
        "def generate_script_openai(title: str, summary: str, tone: str = \"neutral, engaging\", word_target: int = 110) -> str:\n",
        "    \"\"\"\n",
        "    Robust OpenAI generator that extracts the reply text regardless of the\n",
        "    exact response object shape returned by different openai-python versions.\n",
        "    \"\"\"\n",
        "    if client is None:\n",
        "        raise RuntimeError(\"OpenAI client not available\")\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You are a concise, engaging news narrator for short-form videos. \"\n",
        "        \"Produce a single short narration suitable for a 30–60 second video.\"\n",
        "    )\n",
        "    user_prompt = (\n",
        "        f\"Headline: {title}\\n\\n\"\n",
        "        f\"Summary/Context: {summary}\\n\\n\"\n",
        "        \"Requirements:\\n\"\n",
        "        f\"- Produce ~{word_target} words (approximate) — enough for a 30–60 second spoken narration.\\n\"\n",
        "        \"- Use short, clear sentences. No bullet lists or extra sections.\\n\"\n",
        "        \"- Start with a 1-line hook (1 short sentence) to grab attention.\\n\"\n",
        "        \"- Then provide 2–3 sentences that explain the core info.\\n\"\n",
        "        \"- End with one 1-line closing sentence (a concise wrap-up or call-to-action).\\n\"\n",
        "        f\"- Tone: {tone}.\\n\"\n",
        "        \"Return only the narration text. Do not add metadata or commentary.\"\n",
        "    )\n",
        "\n",
        "    # call the chat completions endpoint on the modern client\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        max_tokens=320,\n",
        "        temperature=0.25\n",
        "    )\n",
        "\n",
        "    # resp.choices may be a list-like; try to extract content robustly\n",
        "    try:\n",
        "        choices = getattr(resp, \"choices\", None) or resp.get(\"choices\") if isinstance(resp, dict) else None\n",
        "        if not choices:\n",
        "            # sometimes resp itself is a single choice-like object\n",
        "            text_candidate = _extract_text_from_choice(resp)\n",
        "            if text_candidate:\n",
        "                return text_candidate.strip()\n",
        "        # iterate choices and extract the first non-empty content\n",
        "        for ch in choices:\n",
        "            txt = _extract_text_from_choice(ch)\n",
        "            if txt and txt.strip():\n",
        "                return txt.strip()\n",
        "    except Exception as e:\n",
        "        logging.warning(\"Failed to parse OpenAI response shape: %s\", e)\n",
        "\n",
        "    # final fallback: try direct string\n",
        "    try:\n",
        "        return str(resp)\n",
        "    except Exception:\n",
        "        raise RuntimeError(\"Unable to extract text from OpenAI response\")\n",
        "\n",
        "# Keep the fallback generator you already have (ensure defined in your notebook).\n",
        "# Example minimal fallback if not present:\n",
        "def split_sentences_regex(text: str):\n",
        "    import re\n",
        "    if not text:\n",
        "        return []\n",
        "    sents = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
        "    return [s.strip() for s in sents if s.strip()]\n",
        "\n",
        "def generate_script_fallback(title: str, summary: str, tone: str = \"neutral, engaging\", word_target: int = 110) -> str:\n",
        "    summary = (summary or \"\").strip()\n",
        "    if not summary:\n",
        "        hook = title if len(title.split()) <= 12 else \"Here's a quick update:\"\n",
        "        return f\"{hook} {title}. Stay tuned for more updates.\"\n",
        "\n",
        "    sents = split_sentences_regex(summary)\n",
        "    selected = []\n",
        "    for sent in sents:\n",
        "        if len(selected) >= 3:\n",
        "            break\n",
        "        if len(sent.split()) > 45:\n",
        "            parts = re.split(r',\\s*', sent)\n",
        "            candidate = parts[0].strip() + ('.' if not parts[0].strip().endswith(('.', '!', '?')) else '')\n",
        "            selected.append(candidate)\n",
        "        else:\n",
        "            selected.append(sent if sent.endswith(('.', '!', '?')) else sent + '.')\n",
        "    hook = title if len(title.split()) <= 12 else \"Here's an update:\"\n",
        "    body = \" \".join(selected).strip()\n",
        "    closing = \"Stay tuned for more updates.\"\n",
        "    script = f\"{hook} {body} {closing}\"\n",
        "    words = script.split()\n",
        "    if len(words) > word_target + 20:\n",
        "        script = \" \".join(words[:word_target]).rstrip()\n",
        "        if not script.endswith(('.', '!', '?')):\n",
        "            script = script + '.'\n",
        "    return script\n",
        "\n",
        "# Unified generator wrapper remains the same:\n",
        "def generate_script(title: str, summary: str, tone: str = \"neutral, engaging\", word_target: int = 110) -> str:\n",
        "    try:\n",
        "        if client:\n",
        "            return generate_script_openai(title=title, summary=summary, tone=tone, word_target=word_target)\n",
        "    except Exception as e:\n",
        "        logging.warning(\"OpenAI generation failed, using fallback: %s\", e)\n",
        "    return generate_script_fallback(title=title, summary=summary, tone=tone, word_target=word_target)\n",
        "\n",
        "# If you want to sanity-check: call generate_script on a sample:\n",
        "# print(generate_script(\"Sample Headline\", \"This is a sample summary sentence. Another sentence for test.\"))\n"
      ],
      "metadata": {
        "id": "Enn57tiX4fi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Diagnostic cell — run this to check what's happening (Colab)\n",
        "import os, json, logging, re, time\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
        "\n",
        "print(\"===== Diagnostic start =====\")\n",
        "OPENAI_KEY = os.environ.get(\"OPENAI_KEY\") or \"\"\n",
        "print(\"OPENAI_KEY set in env:\", bool(OPENAI_KEY))\n",
        "\n",
        "client = None\n",
        "if OPENAI_KEY:\n",
        "    try:\n",
        "        from openai import OpenAI\n",
        "        client = OpenAI(api_key=OPENAI_KEY)\n",
        "        print(\"OpenAI client initialized:\", bool(client))\n",
        "    except Exception as e:\n",
        "        print(\"OpenAI client initialization FAILED:\", repr(e))\n",
        "else:\n",
        "    print(\"No OpenAI key — will use fallback generator only.\")\n",
        "\n",
        "# Simple robust extractor (for safety when we call client)\n",
        "def _extract_text_from_choice(choice):\n",
        "    try:\n",
        "        msg = getattr(choice, \"message\", None)\n",
        "        if msg:\n",
        "            if isinstance(msg, dict):\n",
        "                c = msg.get(\"content\")\n",
        "                if c: return c\n",
        "            c = getattr(msg, \"content\", None)\n",
        "            if c: return c\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        txt = getattr(choice, \"text\", None)\n",
        "        if txt: return txt\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        if isinstance(choice, dict):\n",
        "            msg = choice.get(\"message\")\n",
        "            if isinstance(msg, dict):\n",
        "                c = msg.get(\"content\")\n",
        "                if c: return c\n",
        "            t = choice.get(\"text\")\n",
        "            if t: return t\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        return str(choice)\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "# Test OpenAI generation if client present\n",
        "def test_openai():\n",
        "    try:\n",
        "        if not client:\n",
        "            print(\"Skipping OpenAI test (no client).\")\n",
        "            return\n",
        "        print(\"Running small OpenAI test (one request)...\")\n",
        "        resp = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\":\"system\",\"content\":\"You are a tester bot.\"},\n",
        "                {\"role\":\"user\",\"content\":\"Say hi in one short sentence.\"}\n",
        "            ],\n",
        "            max_tokens=30,\n",
        "            temperature=0.0\n",
        "        )\n",
        "        choices = getattr(resp, \"choices\", None) or (resp.get(\"choices\") if isinstance(resp, dict) else None)\n",
        "        if not choices:\n",
        "            txt = _extract_text_from_choice(resp)\n",
        "            print(\"OpenAI response (single):\", repr(txt))\n",
        "            return\n",
        "        for ch in choices:\n",
        "            txt = _extract_text_from_choice(ch)\n",
        "            if txt:\n",
        "                print(\"OpenAI response (choice):\", repr(txt.strip()))\n",
        "                return\n",
        "        print(\"OpenAI response contained no extracted text; raw resp repr:\")\n",
        "        print(resp)\n",
        "    except Exception as e:\n",
        "        print(\"OpenAI test failed:\", repr(e))\n",
        "\n",
        "# Local fallback generator (regex sentence splitter)\n",
        "def split_sentences_regex(text):\n",
        "    if not text: return []\n",
        "    sents = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
        "    return [s.strip() for s in sents if s.strip()]\n",
        "\n",
        "def generate_script_fallback(title, summary, tone=\"neutral, engaging\", word_target=110):\n",
        "    summary = (summary or \"\").strip()\n",
        "    if not summary:\n",
        "        hook = title if len(title.split()) <= 12 else \"Here's a quick update:\"\n",
        "        return f\"{hook} {title}. Stay tuned for more updates.\"\n",
        "    sents = split_sentences_regex(summary)\n",
        "    selected = []\n",
        "    for sent in sents:\n",
        "        if len(selected) >= 3:\n",
        "            break\n",
        "        if len(sent.split()) > 45:\n",
        "            parts = re.split(r',\\s*', sent)\n",
        "            candidate = parts[0].strip()\n",
        "            if candidate and not candidate.endswith(('.', '!', '?')):\n",
        "                candidate += '.'\n",
        "            selected.append(candidate)\n",
        "        else:\n",
        "            selected.append(sent if sent.endswith(('.', '!', '?')) else sent + '.')\n",
        "    hook = title if len(title.split()) <= 12 else \"Here's an update:\"\n",
        "    body = \" \".join(selected).strip()\n",
        "    closing = \"Stay tuned for more updates.\"\n",
        "    script = f\"{hook} {body} {closing}\"\n",
        "    words = script.split()\n",
        "    if len(words) > word_target + 20:\n",
        "        script = \" \".join(words[:word_target]).rstrip()\n",
        "        if not script.endswith(('.', '!', '?')):\n",
        "            script += '.'\n",
        "    return script\n",
        "\n",
        "# Run tests\n",
        "test_openai()\n",
        "\n",
        "# Run fallback test\n",
        "print(\"\\nRunning fallback generator test:\")\n",
        "sample_title = \"Sample Headline: Market update\"\n",
        "sample_summary = (\"Stock markets saw mixed trading today as investors digested a string of corporate earnings. \"\n",
        "                  \"Analysts say tech stocks led gains despite concerns over inflation. Trading volumes were moderate.\")\n",
        "fallback_script = generate_script_fallback(sample_title, sample_summary, word_target=80)\n",
        "print(\"Fallback script output:\\n\", fallback_script)\n",
        "\n",
        "# Attempt to generate from your articles file if it exists\n",
        "ARTICLES_PATH = \"/content/trending_news.json\"\n",
        "if os.path.exists(ARTICLES_PATH):\n",
        "    print(\"\\nFound articles file at\", ARTICLES_PATH)\n",
        "    try:\n",
        "        with open(ARTICLES_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "            articles = json.load(f)\n",
        "        if not articles:\n",
        "            print(\"Articles file empty.\")\n",
        "        else:\n",
        "            a = articles[0]\n",
        "            print(\"\\nSample article loaded (title):\", a.get(\"title\"))\n",
        "            # Try OpenAI generation first (if client), else fallback\n",
        "            if client:\n",
        "                try:\n",
        "                    # reuse test call but with prompt for script\n",
        "                    resp = client.chat.completions.create(\n",
        "                        model=\"gpt-4o-mini\",\n",
        "                        messages=[\n",
        "                            {\"role\":\"system\",\"content\":\"You are a concise news narrator.\"},\n",
        "                            {\"role\":\"user\",\"content\": f\"Headline: {a.get('title')}\\nSummary: {a.get('summary')}\\nProduce one short narration of ~90 words.\"}\n",
        "                        ],\n",
        "                        max_tokens=200,\n",
        "                        temperature=0.2\n",
        "                    )\n",
        "                    choices = getattr(resp, \"choices\", None) or (resp.get(\"choices\") if isinstance(resp, dict) else None)\n",
        "                    got = None\n",
        "                    if choices:\n",
        "                        for ch in choices:\n",
        "                            t = _extract_text_from_choice(ch)\n",
        "                            if t:\n",
        "                                got = t.strip(); break\n",
        "                    else:\n",
        "                        got = _extract_text_from_choice(resp)\n",
        "                    print(\"\\nOpenAI-generated script (sample):\\n\", got or \"(no text extracted)\")\n",
        "                except Exception as e:\n",
        "                    print(\"OpenAI generation for article failed; falling back. Error:\", repr(e))\n",
        "                    print(\"\\nFallback script for article:\\n\", generate_script_fallback(a.get('title',''), a.get('summary','')))\n",
        "            else:\n",
        "                print(\"\\nGenerating fallback script from article:\\n\", generate_script_fallback(a.get('title',''), a.get('summary','')))\n",
        "    except Exception as e:\n",
        "        print(\"Failed to read/parse articles file:\", repr(e))\n",
        "else:\n",
        "    print(\"\\nNo articles file found at\", ARTICLES_PATH, \"- run Step 1 (scraper) or change path.\")\n",
        "\n",
        "print(\"\\n===== Diagnostic end =====\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_K8LVKG7ADQ",
        "outputId": "7a1e02e1-1084-4e87-ad04-2bb8d0628b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Diagnostic start =====\n",
            "OPENAI_KEY set in env: True\n",
            "OpenAI client initialized: True\n",
            "Running small OpenAI test (one request)...\n",
            "OpenAI response (choice): 'Hi there!'\n",
            "\n",
            "Running fallback generator test:\n",
            "Fallback script output:\n",
            " Sample Headline: Market update Stock markets saw mixed trading today as investors digested a string of corporate earnings. Analysts say tech stocks led gains despite concerns over inflation. Trading volumes were moderate. Stay tuned for more updates.\n",
            "\n",
            "Found articles file at /content/trending_news.json\n",
            "\n",
            "Sample article loaded (title): Mamata Banerjee demands PM’s apology over ‘Bankim da’ remark in Lok Sabha - The Hindu\n",
            "\n",
            "OpenAI-generated script (sample):\n",
            " West Bengal Chief Minister Mamata Banerjee has called for an apology from Prime Minister Narendra Modi over his remarks referring to 'Bankim da' in the Lok Sabha. This incident has sparked a heated debate, with TMC MPs staging a silent protest against what they perceive as an insult to Bengal's cultural icons. Union Home Minister Amit Shah responded to Priyanka Gandhi's criticisms regarding Vande Mataram and defended the BJP's stance on historical figures like Nehru and Indira Gandhi, intensifying the political discourse surrounding the issue.\n",
            "\n",
            "===== Diagnostic end =====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this in Colab to generate scripts for all articles and save them\n",
        "import os, json\n",
        "ARTICLES_PATH = \"/content/trending_news.json\"   # update if you saved elsewhere\n",
        "OUT_PATH = \"/content/generated_scripts.json\"\n",
        "\n",
        "if not os.path.exists(ARTICLES_PATH):\n",
        "    raise FileNotFoundError(f\"{ARTICLES_PATH} not found. Run the scraper step first or update the path.\")\n",
        "\n",
        "with open(ARTICLES_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    articles = json.load(f)\n",
        "\n",
        "print(f\"Loaded {len(articles)} articles. Generating scripts...\")\n",
        "generated = batch_generate_scripts(articles, tone=\"urgent but factual\", word_target=110, out_path=OUT_PATH)\n",
        "print(f\"Done — generated {len(generated)} scripts and saved to {OUT_PATH}\")\n",
        "\n",
        "# quick preview\n",
        "for i, g in enumerate(generated[:3], start=1):\n",
        "    print(f\"\\n--- Script {i} ({g.get('source')}) ---\\n{g.get('script')[:500]}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWJNJrH77JwF",
        "outputId": "c3e6d6ad-a9c2-447f-f0d5-18f99c596077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 6 articles. Generating scripts...\n",
            "Done — generated 6 scripts and saved to /content/generated_scripts.json\n",
            "\n",
            "--- Script 1 (The Hindu) ---\n",
            "ChatCompletion(id='chatcmpl-CkrpwvjlghlMyFvD4dqxY54Xd0S2W', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Tensions are rising in Indian politics. West Bengal Chief Minister Mamata Banerjee is demanding an apology from Prime Minister Narendra Modi over his controversial \"Bankim da\" remark made in the Lok Sabha. This statement has sparked outrage among TMC MPs, who staged a silent protest, claiming it insults Bengal\\'s cultural icons. Meanwhil\n",
            "\n",
            "\n",
            "--- Script 2 (Hindustan Times) ---\n",
            "ChatCompletion(id='chatcmpl-CkrqKkBGjB4Ai2syMVxCNthfvGIDj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='In a shocking turn of events, Goa nightclub owners Saurabh and Gaurav Luthra fled to Thailand just hours after a devastating fire at their establishment. Reports indicate they boarded a flight shortly after the incident, raising questions about their escape. Meanwhile, the Goa government has initiated the demolition of their Vagator beac\n",
            "\n",
            "\n",
            "--- Script 3 (Hindustan Times) ---\n",
            "ChatCompletion(id='chatcmpl-CkrqhosWoJS3xbG64c80v0vF5JZM3', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Rahul Gandhi is making waves in Parliament! During a heated debate, he posed three critical questions to the government, focusing on the appointment of the Election Commission chief without the Chief Justice of India. He labeled vote rigging as the \"biggest anti-national act\" and demanded transparency in the electoral process. Gandhi\\'s \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"/content/generated_scripts.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(\"Total scripts:\", len(data))\n",
        "print(\"\\nSample script:\\n\")\n",
        "print(data[0][\"script\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQwiMDNr77ZC",
        "outputId": "ff15aa23-c9d8-445c-9f74-db17f6d9d4f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total scripts: 6\n",
            "\n",
            "Sample script:\n",
            "\n",
            "ChatCompletion(id='chatcmpl-CkrpwvjlghlMyFvD4dqxY54Xd0S2W', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Tensions are rising in Indian politics. West Bengal Chief Minister Mamata Banerjee is demanding an apology from Prime Minister Narendra Modi over his controversial \"Bankim da\" remark made in the Lok Sabha. This statement has sparked outrage among TMC MPs, who staged a silent protest, claiming it insults Bengal\\'s cultural icons. Meanwhile, Union Home Minister Amit Shah defended the government\\'s stance on the Vande Mataram debate, igniting further clashes with opposition leaders. As the political landscape heats up, all eyes are on how this controversy will unfold. Stay tuned for more updates on this developing story.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1765286072, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_aa07c96156', usage=CompletionUsage(completion_tokens=120, prompt_tokens=309, total_tokens=429, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FvC7BjZ8Aw0",
        "outputId": "e0df8d20-e6bb-49e3-cd36-e710c4fd1803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/generated_scripts.json /content/drive/MyDrive/generated_scripts.json\n"
      ],
      "metadata": {
        "id": "u_gKgVHX8FWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o8c9hLuQ9Am7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 1: install required libraries\n",
        "!pip install -q moviepy pillow requests gTTS tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MXvw5OrdSWb",
        "outputId": "1dc11370-4727-49cb-bb74-0b72b537c344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/98.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 2: prepare synthetic images + narration audio\n",
        "import os, json, textwrap, pathlib, random\n",
        "from PIL import Image, ImageDraw, ImageFilter, ImageFont\n",
        "from gtts import gTTS\n",
        "\n",
        "ASSETS_DIR = \"/content/assets\"\n",
        "pathlib.Path(ASSETS_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Load the first script\n",
        "SCRIPTS_PATH = \"/content/generated_scripts.json\"\n",
        "with open(SCRIPTS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    scripts = json.load(f)\n",
        "\n",
        "entry = scripts[0]\n",
        "title = entry.get(\"title\", \"News Story\")\n",
        "script_text = entry.get(\"script_180\") or entry.get(\"script\") or entry.get(\"summary\")\n",
        "\n",
        "print(\"Using:\", title)\n",
        "\n",
        "# --- Synthetic cinematic gradient background generator ---\n",
        "def create_gradient_image(out_path, size=(1080,1920), hue_shift=0):\n",
        "    w, h = size\n",
        "    img = Image.new(\"RGB\", (w, h))\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    for y in range(h):\n",
        "        ratio = y / h\n",
        "        r = int(100 + 80 * ratio)\n",
        "        g = int(60 + 140 * (1 - ratio))\n",
        "        b = int(120 + 60 * ratio)\n",
        "        draw.line([(0, y), (w, y)], fill=(r, g, b))\n",
        "\n",
        "    img = img.filter(ImageFilter.GaussianBlur(radius=12))\n",
        "    img.save(out_path, \"JPEG\", quality=90)\n",
        "    return out_path\n",
        "\n",
        "# Create 3 images\n",
        "image_paths = []\n",
        "for i in range(3):\n",
        "    out = f\"{ASSETS_DIR}/bg_{i+1}.jpg\"\n",
        "    create_gradient_image(out)\n",
        "    image_paths.append(out)\n",
        "\n",
        "print(\"Synthetic images created:\", image_paths)\n",
        "\n",
        "# --- Create narration audio using gTTS ---\n",
        "tts_path = f\"{ASSETS_DIR}/narration.mp3\"\n",
        "tts = gTTS(script_text, lang=\"en\")\n",
        "tts.save(tts_path)\n",
        "\n",
        "print(\"Narration saved:\", tts_path)\n",
        "\n",
        "# Save manifest\n",
        "manifest = {\n",
        "    \"title\": title,\n",
        "    \"script\": script_text,\n",
        "    \"images\": image_paths,\n",
        "    \"audio\": tts_path\n",
        "}\n",
        "with open(f\"{ASSETS_DIR}/manifest.json\", \"w\") as f:\n",
        "    json.dump(manifest, f, indent=2)\n",
        "\n",
        "print(\"Assets ready in\", ASSETS_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0lwkbh6eSQm",
        "outputId": "6d685c19-98bd-4496-bc2e-4fdb90dda08d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: Mamata Banerjee demands PM’s apology over ‘Bankim da’ remark in Lok Sabha - The Hindu\n",
            "Synthetic images created: ['/content/assets/bg_1.jpg', '/content/assets/bg_2.jpg', '/content/assets/bg_3.jpg']\n",
            "Narration saved: /content/assets/narration.mp3\n",
            "Assets ready in /content/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed MoviePy assembly cell — renders caption PNGs using PIL.draw.textbbox (no ImageMagick)\n",
        "from moviepy.editor import ImageClip, AudioFileClip, CompositeVideoClip, concatenate_videoclips, vfx\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import textwrap, json, os, pathlib\n",
        "\n",
        "ASSETS_DIR = \"/content/assets\"\n",
        "with open(os.path.join(ASSETS_DIR, \"manifest.json\"), \"r\", encoding=\"utf-8\") as f:\n",
        "    manifest = json.load(f)\n",
        "\n",
        "images = manifest[\"images\"]\n",
        "audio_path = manifest[\"audio\"]\n",
        "script_text = manifest[\"script\"]\n",
        "\n",
        "audio = AudioFileClip(audio_path)\n",
        "duration = audio.duration\n",
        "\n",
        "W, H = 1080, 1920\n",
        "segments = len(images)\n",
        "segment_dur = max(2.0, duration / segments)  # ensure at least 2s per image\n",
        "\n",
        "# split caption text into segments\n",
        "words = script_text.split()\n",
        "if len(words) < 1:\n",
        "    words = [\" \"]\n",
        "words_per_seg = max(8, len(words) // segments)\n",
        "captions = []\n",
        "for i in range(segments):\n",
        "    start = i * words_per_seg\n",
        "    end = (i + 1) * words_per_seg if i < segments - 1 else len(words)\n",
        "    seg = \" \".join(words[start:end]).strip()\n",
        "    if not seg:\n",
        "        seg = \"...\"\n",
        "    captions.append(seg)\n",
        "\n",
        "# utility: create caption PNG using PIL (robust measurement using textbbox)\n",
        "def create_caption_png(text, out_path, width=W-120, fontsize=56, font_path=None, fill=(255,255,255,255), bg=(0,0,0,180)):\n",
        "    \"\"\"\n",
        "    Render wrapped text into a transparent PNG sized to width. Returns path.\n",
        "    Uses ImageDraw.textbbox for reliable measurements across PIL versions.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if font_path and os.path.exists(font_path):\n",
        "            font = ImageFont.truetype(font_path, fontsize)\n",
        "        else:\n",
        "            font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", fontsize)\n",
        "    except Exception:\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "    # wrap text into lines fitting the width\n",
        "    words = text.split()\n",
        "    lines = []\n",
        "    line = \"\"\n",
        "    # create a temporary image/draw for measurement\n",
        "    tmp_img = Image.new(\"RGBA\", (10,10), (0,0,0,0))\n",
        "    tmp_draw = ImageDraw.Draw(tmp_img)\n",
        "    for w in words:\n",
        "        test = (line + \" \" + w).strip()\n",
        "        bbox = tmp_draw.textbbox((0,0), test, font=font)\n",
        "        test_w = bbox[2] - bbox[0]\n",
        "        if test_w <= width:\n",
        "            line = test\n",
        "        else:\n",
        "            if line:\n",
        "                lines.append(line)\n",
        "            line = w\n",
        "    if line:\n",
        "        lines.append(line)\n",
        "\n",
        "    # measure height\n",
        "    bbox = tmp_draw.textbbox((0,0), \"Ay\", font=font)\n",
        "    line_height = (bbox[3] - bbox[1]) + 8\n",
        "    img_h = line_height * len(lines) + 40\n",
        "    img_w = width + 40\n",
        "\n",
        "    # create image with transparent bg and semi-opaque rounded rectangle\n",
        "    img = Image.new(\"RGBA\", (img_w, img_h), (0,0,0,0))\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    # draw semi-opaque rounded rectangle for readability\n",
        "    rect_margin = 8\n",
        "    rect = [rect_margin, rect_margin, img_w-rect_margin, img_h-rect_margin]\n",
        "    radius = 18\n",
        "    overlay = Image.new(\"RGBA\", (img_w, img_h), (0,0,0,0))\n",
        "    od = ImageDraw.Draw(overlay)\n",
        "    # Pillow supports rounded_rectangle in modern versions; fallback to rectangle if not\n",
        "    try:\n",
        "        od.rounded_rectangle(rect, radius=radius, fill=bg)\n",
        "        img = Image.alpha_composite(img, overlay)\n",
        "    except Exception:\n",
        "        od.rectangle(rect, fill=bg)\n",
        "        img = Image.alpha_composite(img, overlay)\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    # draw centered text lines\n",
        "    y = 20\n",
        "    for ln in lines:\n",
        "        bbox = draw.textbbox((0,0), ln, font=font)\n",
        "        w_text = bbox[2] - bbox[0]\n",
        "        x = (img_w - w_text) // 2\n",
        "        draw.text((x, y), ln, font=font, fill=fill)\n",
        "        y += line_height\n",
        "\n",
        "    # save PNG\n",
        "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
        "    img.save(out_path, format=\"PNG\")\n",
        "    return out_path\n",
        "\n",
        "# create caption pngs\n",
        "pathlib.Path(ASSETS_DIR).mkdir(parents=True, exist_ok=True)\n",
        "caption_paths = []\n",
        "for idx, cap in enumerate(captions, start=1):\n",
        "    outp = os.path.join(ASSETS_DIR, f\"caption_{idx}.png\")\n",
        "    create_caption_png(cap, outp, fontsize=56)\n",
        "    caption_paths.append(outp)\n",
        "\n",
        "# Build clips\n",
        "clips = []\n",
        "for img_path, cap_path in zip(images, caption_paths):\n",
        "    # base image -> ensure it fills vertical frame\n",
        "    base = ImageClip(img_path).set_duration(segment_dur)\n",
        "\n",
        "    # resize to at least H height then center-crop to WxH\n",
        "    base = base.resize(height=H)\n",
        "    if base.w > W:\n",
        "        x1 = int((base.w - W) / 2)\n",
        "        base = base.crop(x1=x1, width=W)\n",
        "    else:\n",
        "        base = base.resize(width=W)\n",
        "\n",
        "    # apply slow zoom-in (Ken Burns)\n",
        "    base = base.fx(vfx.resize, lambda t: 1 + 0.02 * t)\n",
        "\n",
        "    # caption image clip (small, positioned above bottom)\n",
        "    caption_clip = ImageClip(cap_path).set_duration(segment_dur)\n",
        "    if caption_clip.w > (W - 60):\n",
        "        caption_clip = caption_clip.resize(width=(W - 60))\n",
        "    caption_clip = caption_clip.set_position((\"center\", H - 360))\n",
        "\n",
        "    comp = CompositeVideoClip([base, caption_clip], size=(W, H)).set_duration(segment_dur)\n",
        "    clips.append(comp)\n",
        "\n",
        "# Concatenate and set audio\n",
        "video = concatenate_videoclips(clips, method=\"compose\")\n",
        "\n",
        "# adjust duration to match audio if needed\n",
        "if abs(video.duration - audio.duration) > 0.1:\n",
        "    if video.duration < audio.duration:\n",
        "        extra = audio.duration - video.duration\n",
        "        last = clips[-1].set_duration(clips[-1].duration + extra)\n",
        "        clips[-1] = last\n",
        "        video = concatenate_videoclips(clips, method=\"compose\")\n",
        "    else:\n",
        "        video = video.subclip(0, audio.duration)\n",
        "\n",
        "video = video.set_audio(audio)\n",
        "\n",
        "OUT_PATH = \"/content/final_moviepy_video_no_imagemagick_v2.mp4\"\n",
        "print(\"Rendering final video to:\", OUT_PATH)\n",
        "video.write_videofile(OUT_PATH, fps=24, codec=\"libx264\", audio_codec=\"aac\", threads=4, bitrate=\"4M\")\n",
        "\n",
        "print(\"Final video saved to:\", OUT_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB4uJubifwTV",
        "outputId": "cf16a75a-7a12-4829-a882-32f7b4e4a92e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rendering final video to: /content/final_moviepy_video_no_imagemagick_v2.mp4\n",
            "Moviepy - Building video /content/final_moviepy_video_no_imagemagick_v2.mp4.\n",
            "MoviePy - Writing audio in final_moviepy_video_no_imagemagick_v2TEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video /content/final_moviepy_video_no_imagemagick_v2.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/final_moviepy_video_no_imagemagick_v2.mp4\n",
            "Final video saved to: /content/final_moviepy_video_no_imagemagick_v2.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/final_moviepy_video_no_imagemagick_v2.mp4\" \"/content/drive/MyDrive/\"\n",
        "print(\"Saved to Google Drive → MyDrive folder\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g88Renw5kmVT",
        "outputId": "60b28355-92ad-45cb-a40f-9fe6a455d29e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to Google Drive → MyDrive folder\n"
          ]
        }
      ]
    }
  ]
}